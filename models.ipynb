{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2db4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3069a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f669204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.Defaults.stop_words -= {\"not\", \"do\"}\n",
    "from autocorrect import Speller\n",
    "nltk.download('words', quiet=True)\n",
    "import emoji\n",
    "import sqlite3\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import contractions\n",
    "nltk.download('wordnet', quiet=True)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from pprint import pprint\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561059f",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64396c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"IMDB_Movies_2021.db\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "table_name = \"REVIEWS\"\n",
    "\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc7536",
   "metadata": {},
   "source": [
    "# Drop duplicates and remove nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27604dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset = ['REVIEW','AUTHOR'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d812a",
   "metadata": {},
   "source": [
    "# Combine review and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf001935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIXED_REVIEW'] = df['REVIEW'] +df['TITLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d05229",
   "metadata": {},
   "source": [
    "# Simple preprocesing: lowercase, punctuation, emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82a80df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIXED_REVIEW'] = [review.lower() for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [re.sub(r'[^a-zA-Z\\s]', '', review) for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [re.sub(r'@\\w+', '', review) for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [re.sub(r'#\\w+', '', review) for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [re.sub(r'http\\S+|www\\S+|https\\S+', '', review) for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [emoji.demojize(review) for review in df['FIXED_REVIEW']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbc286",
   "metadata": {},
   "source": [
    "# Remove stop short and long words, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466b3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('no')\n",
    "def sentiment(word):\n",
    "    blob = TextBlob(word)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    return np.abs(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "402c2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    text = contractions.fix(text)\n",
    "    words = text.split()    # Tokenize the text into words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    filtered_words = [word for word in filtered_words if len(word) > 2]\n",
    "    filtered_words = [word for word in filtered_words if len(word) < 8]\n",
    "    filtered_words = [word for word in filtered_words if sentiment(word) != 0 ]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5cea2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('omw-1.4', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96978f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIXED_REVIEW'] = df['FIXED_REVIEW'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c186bc",
   "metadata": {},
   "source": [
    "# Remove misspelt words (maybe replace with better method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74aeddcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cecbc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "setofwords = set(words.words())\n",
    "\n",
    "print(\"hello\" in setofwords)\n",
    "\n",
    "j = 0\n",
    "new_review = []\n",
    "\n",
    "for i in df['FIXED_REVIEW']:\n",
    "    words = word_tokenize(i)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word in setofwords:\n",
    "            new_words.append(word)\n",
    "    sentence_correct = ' '.join(new_words)        \n",
    "    new_review.append(sentence_correct)\n",
    "    #df['FIXED_REVIEW'][j] = sentence_correct\n",
    "    j+=1\n",
    "\n",
    "\n",
    "df['FIXED_REVIEW'] = new_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a138e5",
   "metadata": {},
   "source": [
    "# Add our target (ie: class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0030848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_race(row):\n",
    "    if row['RATING'] >= 7:\n",
    "        return 2\n",
    "    if row['RATING'] <= 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['CLASS'] = df.apply(label_race, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc910a43",
   "metadata": {},
   "source": [
    "# Add sentiment as column (can add more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "807aaf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_1(text):\n",
    "    return TextBlob(text).sentiment.polarity \n",
    "df['sentiment_1'] = df['FIXED_REVIEW'].apply(get_sentiment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32efd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)\n",
    "    compound_score = sentiment_score['compound']\n",
    "    \n",
    "    return compound_score\n",
    "\n",
    "def vader_class(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)\n",
    "    compound_score = sentiment_score['compound']\n",
    "    \n",
    "    if compound_score > 0.1:\n",
    "        sentiment = 2\n",
    "    elif compound_score < -0.1:\n",
    "        sentiment = 0\n",
    "    else:\n",
    "        sentiment = 1\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ddc8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_sentiment'] = df['FIXED_REVIEW'].apply(vader_sentiment)\n",
    "df['vader_class'] = df['FIXED_REVIEW'].apply(vader_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242c44f",
   "metadata": {},
   "source": [
    "# Add a tokenized column for topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a6f8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7c5926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_review'] = df['FIXED_REVIEW'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ff2ce",
   "metadata": {},
   "source": [
    "# Now use LDA for topics, gives additional context (may need to optimise how many topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12d52915",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df['tokenized_review'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['tokenized_review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d45584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, passes=20, alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95129f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = [lda_model.get_document_topics(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32d479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_matrix = []\n",
    "for dist in topic_distributions:\n",
    "    topic_vector = [0] * 10  # Number of topics (in this case 2)\n",
    "    for topic_id, prob in dist:\n",
    "        topic_vector[topic_id] = prob\n",
    "    topic_matrix.append(topic_vector)\n",
    "\n",
    "# Convert topic_matrix to a DataFrame for easy handling\n",
    "topic_df = pd.DataFrame(topic_matrix, columns=[f\"topic_{i}\" for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fd3a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, topic_df], axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ee84b",
   "metadata": {},
   "source": [
    "# Now BOW with tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d457eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer(ngram_range = (1,2))\n",
    "bow = v.fit_transform(df.FIXED_REVIEW.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "596da57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = pd.DataFrame.sparse.from_spmatrix(bow, columns = v.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc140126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, bow], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6618412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['ID','RATING','REVIEW','TITLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5712c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a55a36",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f773b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7df82",
   "metadata": {},
   "source": [
    "# Using the data in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aff3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and y\n",
    "X = df.drop(columns = ['CLASS', 'AUTHOR','FIXED_REVIEW','tokenized_review'])\n",
    "y = df['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a45baf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiment_1', 'vader_sentiment', 'vader_class', 'topic_0', 'topic_1',\n",
       "       'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6',\n",
       "       ...\n",
       "       'young useless', 'young vicious', 'young victim', 'young violent',\n",
       "       'young vivid', 'young whole', 'young wide', 'young willing',\n",
       "       'young wrong', 'young young'],\n",
       "      dtype='object', length=17268)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec6e53",
   "metadata": {},
   "source": [
    "# Best 15 features applying correlation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fecc99ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['vader_sentiment', 'sentiment_1', 'vader_class', 'topic_0', 'topic_6', 'bad', 'waste', 'funny', 'amazing', 'fly', 'topic_9', 'topic_7', 'perfect', 'worst', 'awful', 'great', 'rose', 'topic_4', 'really', 'past']\n"
     ]
    }
   ],
   "source": [
    "def correlation_feature_selection(X, y, top_k=10):\n",
    "    corr_matrix = X.corrwith(y).abs().sort_values(ascending=False)\n",
    "    top_features = corr_matrix.head(top_k).index.tolist()\n",
    "    return X[top_features]\n",
    "\n",
    "# Select top 15 features\n",
    "X_selected = correlation_feature_selection(X, y, top_k=20)\n",
    "print(\"Selected Features:\", X_selected.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eedf4a",
   "metadata": {},
   "source": [
    "# We will need to iterate with different k values to find best k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175fbf7",
   "metadata": {},
   "source": [
    "# Another feature selection method is pca (this finds ten features via pca)\n",
    "\n",
    "## Again need to find optimum k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a05f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if isinstance(X_selected, pd.DataFrame) and X_selected.dtypes.apply(lambda x: x.name == 'Sparse[int64]').any():\n",
    "    X_selected = X_selected.sparse.to_dense()\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  \n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "k = 10\n",
    "pca = PCA(n_components=k)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_pca = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48691e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.904771</td>\n",
       "      <td>-0.092091</td>\n",
       "      <td>-0.086070</td>\n",
       "      <td>-0.443140</td>\n",
       "      <td>-0.260418</td>\n",
       "      <td>1.142161</td>\n",
       "      <td>0.787700</td>\n",
       "      <td>0.719729</td>\n",
       "      <td>-0.171565</td>\n",
       "      <td>0.078674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.268911</td>\n",
       "      <td>-0.768071</td>\n",
       "      <td>-0.842730</td>\n",
       "      <td>0.628006</td>\n",
       "      <td>-0.371933</td>\n",
       "      <td>1.290464</td>\n",
       "      <td>0.709102</td>\n",
       "      <td>0.407629</td>\n",
       "      <td>-0.272236</td>\n",
       "      <td>-0.311757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.566084</td>\n",
       "      <td>0.129820</td>\n",
       "      <td>-1.389244</td>\n",
       "      <td>0.947614</td>\n",
       "      <td>0.691967</td>\n",
       "      <td>0.021257</td>\n",
       "      <td>-0.694549</td>\n",
       "      <td>-0.549174</td>\n",
       "      <td>0.035403</td>\n",
       "      <td>-0.437488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.979433</td>\n",
       "      <td>-0.020297</td>\n",
       "      <td>1.420527</td>\n",
       "      <td>-0.709071</td>\n",
       "      <td>0.371252</td>\n",
       "      <td>-0.630289</td>\n",
       "      <td>-0.138900</td>\n",
       "      <td>-0.324328</td>\n",
       "      <td>-0.176987</td>\n",
       "      <td>-0.087633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.314656</td>\n",
       "      <td>-0.071529</td>\n",
       "      <td>-0.070086</td>\n",
       "      <td>-2.510746</td>\n",
       "      <td>2.151323</td>\n",
       "      <td>-0.239839</td>\n",
       "      <td>-0.210476</td>\n",
       "      <td>-0.215276</td>\n",
       "      <td>0.069687</td>\n",
       "      <td>0.038133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>1.886401</td>\n",
       "      <td>-1.788384</td>\n",
       "      <td>-0.249870</td>\n",
       "      <td>-0.214195</td>\n",
       "      <td>-0.842731</td>\n",
       "      <td>-1.148162</td>\n",
       "      <td>0.148333</td>\n",
       "      <td>0.067218</td>\n",
       "      <td>-0.307993</td>\n",
       "      <td>-0.835734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5073</th>\n",
       "      <td>1.841146</td>\n",
       "      <td>-0.351336</td>\n",
       "      <td>0.021547</td>\n",
       "      <td>-2.276560</td>\n",
       "      <td>0.358392</td>\n",
       "      <td>-0.710218</td>\n",
       "      <td>0.239007</td>\n",
       "      <td>-0.034893</td>\n",
       "      <td>-0.518241</td>\n",
       "      <td>-0.025587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5074</th>\n",
       "      <td>2.655401</td>\n",
       "      <td>-1.002513</td>\n",
       "      <td>1.502082</td>\n",
       "      <td>-0.047428</td>\n",
       "      <td>-0.860252</td>\n",
       "      <td>-0.924158</td>\n",
       "      <td>-0.086556</td>\n",
       "      <td>-0.184779</td>\n",
       "      <td>-0.464846</td>\n",
       "      <td>0.044854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>2.376168</td>\n",
       "      <td>-0.392854</td>\n",
       "      <td>0.521726</td>\n",
       "      <td>-1.146889</td>\n",
       "      <td>-2.682512</td>\n",
       "      <td>-1.684893</td>\n",
       "      <td>0.614627</td>\n",
       "      <td>0.050976</td>\n",
       "      <td>-1.124706</td>\n",
       "      <td>-0.117780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>1.638721</td>\n",
       "      <td>-0.223058</td>\n",
       "      <td>0.260803</td>\n",
       "      <td>0.240286</td>\n",
       "      <td>-1.404539</td>\n",
       "      <td>-1.656561</td>\n",
       "      <td>-0.355915</td>\n",
       "      <td>-0.410085</td>\n",
       "      <td>-0.706247</td>\n",
       "      <td>-0.139006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5077 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0     1.904771 -0.092091 -0.086070 -0.443140 -0.260418  1.142161  0.787700   \n",
       "1    -0.268911 -0.768071 -0.842730  0.628006 -0.371933  1.290464  0.709102   \n",
       "2    -1.566084  0.129820 -1.389244  0.947614  0.691967  0.021257 -0.694549   \n",
       "3    -0.979433 -0.020297  1.420527 -0.709071  0.371252 -0.630289 -0.138900   \n",
       "4     0.314656 -0.071529 -0.070086 -2.510746  2.151323 -0.239839 -0.210476   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5072  1.886401 -1.788384 -0.249870 -0.214195 -0.842731 -1.148162  0.148333   \n",
       "5073  1.841146 -0.351336  0.021547 -2.276560  0.358392 -0.710218  0.239007   \n",
       "5074  2.655401 -1.002513  1.502082 -0.047428 -0.860252 -0.924158 -0.086556   \n",
       "5075  2.376168 -0.392854  0.521726 -1.146889 -2.682512 -1.684893  0.614627   \n",
       "5076  1.638721 -0.223058  0.260803  0.240286 -1.404539 -1.656561 -0.355915   \n",
       "\n",
       "           PC8       PC9      PC10  \n",
       "0     0.719729 -0.171565  0.078674  \n",
       "1     0.407629 -0.272236 -0.311757  \n",
       "2    -0.549174  0.035403 -0.437488  \n",
       "3    -0.324328 -0.176987 -0.087633  \n",
       "4    -0.215276  0.069687  0.038133  \n",
       "...        ...       ...       ...  \n",
       "5072  0.067218 -0.307993 -0.835734  \n",
       "5073 -0.034893 -0.518241 -0.025587  \n",
       "5074 -0.184779 -0.464846  0.044854  \n",
       "5075  0.050976 -1.124706 -0.117780  \n",
       "5076 -0.410085 -0.706247 -0.139006  \n",
       "\n",
       "[5077 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e2fc0",
   "metadata": {},
   "source": [
    "# LASSO TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc942ffd",
   "metadata": {},
   "source": [
    "# Now onto our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b1759c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=51, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267f0bd",
   "metadata": {},
   "source": [
    "# Multinomial Logisitc Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b131eaf4",
   "metadata": {},
   "source": [
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfc78f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.66      0.68       388\n",
      "         1.0       0.21      0.15      0.17       211\n",
      "         2.0       0.63      0.76      0.69       417\n",
      "\n",
      "    accuracy                           0.59      1016\n",
      "   macro avg       0.51      0.52      0.51      1016\n",
      "weighted avg       0.57      0.59      0.58      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_mlr = LogisticRegression(multi_class='multinomial', solver='lbfgs',\n",
    "                                   class_weight='balanced', max_iter=1000)\n",
    "\n",
    "model_mlr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_mlr.predict(X_test)\n",
    "print(\"Initial Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a027c1da",
   "metadata": {},
   "source": [
    "### MLR - Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "94fd86f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import GridSearchCV'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'C': 1e-05, 'solver': 'lbfgs'}\n",
      "\n",
      "Tuned Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.72      0.70       388\n",
      "         1.0       0.24      0.02      0.04       211\n",
      "         2.0       0.60      0.84      0.70       417\n",
      "\n",
      "    accuracy                           0.62      1016\n",
      "   macro avg       0.51      0.53      0.48      1016\n",
      "weighted avg       0.56      0.62      0.56      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(multi_class='multinomial', class_weight='balanced', max_iter=1000),\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters:\", grid.best_params_)\n",
    "\n",
    "y_pred_tuned = grid.predict(X_test)\n",
    "print(\"\\nTuned Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_tuned, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a8a0ee",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9fe7c8",
   "metadata": {},
   "source": [
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e20923b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.69      0.65       388\n",
      "         1.0       0.16      0.08      0.10       211\n",
      "         2.0       0.61      0.71      0.65       417\n",
      "\n",
      "    accuracy                           0.57      1016\n",
      "   macro avg       0.46      0.49      0.47      1016\n",
      "weighted avg       0.52      0.57      0.54      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=51, class_weight='balanced')\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred = model_rf.predict(X_test)\n",
    "\n",
    "print(\"\\nInitial Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb79a4e",
   "metadata": {},
   "source": [
    "### RF - Hyperparameter Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "62e4b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 183}\n",
      "\n",
      "Tuned RF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.78      0.71       388\n",
      "         1.0       0.31      0.07      0.12       211\n",
      "         2.0       0.64      0.78      0.70       417\n",
      "\n",
      "    accuracy                           0.63      1016\n",
      "   macro avg       0.53      0.54      0.51      1016\n",
      "weighted avg       0.58      0.63      0.58      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': randint(50, 500),\n",
    "    'max_depth': randint(1, 20),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=model_rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=27\n",
    ")\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\", rand_search.best_params_)\n",
    "\n",
    "print(\"\\nTuned RF Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dbce9",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4586d109",
   "metadata": {},
   "source": [
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f06800c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.65      0.68       388\n",
      "         1.0       0.21      0.08      0.11       211\n",
      "         2.0       0.61      0.84      0.71       417\n",
      "\n",
      "    accuracy                           0.61      1016\n",
      "   macro avg       0.50      0.52      0.50      1016\n",
      "weighted avg       0.56      0.61      0.57      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_svm = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_svm.predict(X_test)\n",
    "print(\"\\nInitial Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa75919",
   "metadata": {},
   "source": [
    "### SVM - RandomizedSearchCV for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf64255e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'C': 4.267214105188957, 'degree': 2, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "\n",
      "Tuned Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.65      0.68       388\n",
      "         1.0       0.21      0.08      0.11       211\n",
      "         2.0       0.61      0.84      0.70       417\n",
      "\n",
      "    accuracy                           0.61      1016\n",
      "   macro avg       0.51      0.52      0.50      1016\n",
      "weighted avg       0.56      0.61      0.57      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "param_dist = {\n",
    "    'C': uniform(0.01, 10),\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3, 4],\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=svm.SVC(class_weight='balanced'),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=27\n",
    ")\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "best_svm = rand_search.best_estimator_\n",
    "y_pred_best = best_svm.predict(X_test)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\", rand_search.best_params_)\n",
    "print(\"\\nTuned Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7c5df5",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57a6fc",
   "metadata": {},
   "source": [
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77b41030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.72      0.67       388\n",
      "         1.0       0.23      0.09      0.13       211\n",
      "         2.0       0.63      0.74      0.68       417\n",
      "\n",
      "    accuracy                           0.60      1016\n",
      "   macro avg       0.50      0.52      0.49      1016\n",
      "weighted avg       0.55      0.60      0.56      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(objective='multi:softmax', num_class=3, eval_metric='mlogloss')\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "print(\"\\nInitial Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ab0e2",
   "metadata": {},
   "source": [
    "### XGBoost - RandomizedSearchCV for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e02ef051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'colsample_bytree': 0.7128607052594479, 'gamma': 4.072918702472763, 'learning_rate': 0.2306191870599039, 'max_depth': 8, 'n_estimators': 74, 'reg_alpha': 0.3833807728726202, 'reg_lambda': 5.897283160722603, 'subsample': 0.9465971733575677}\n",
      "\n",
      "Tuned Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.77      0.70       388\n",
      "         1.0       0.22      0.02      0.03       211\n",
      "         2.0       0.62      0.79      0.70       417\n",
      "\n",
      "    accuracy                           0.62      1016\n",
      "   macro avg       0.49      0.53      0.48      1016\n",
      "weighted avg       0.55      0.62      0.56      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 500),       \n",
    "    'max_depth': randint(3, 15),      \n",
    "    'learning_rate': uniform(0.01, 0.3),   \n",
    "    'subsample': uniform(0.5, 0.5),      \n",
    "    'colsample_bytree': uniform(0.5, 0.5), \n",
    "    'gamma': uniform(0, 5),       \n",
    "    'reg_alpha': uniform(0, 1),  \n",
    "    'reg_lambda': uniform(1, 5)   \n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(objective='multi:softmax', num_class=3, eval_metric='mlogloss', use_label_encoder=False),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,              \n",
    "    cv=5,                \n",
    "    scoring='accuracy',  \n",
    "    n_jobs=-1,      \n",
    "    random_state=27\n",
    ")\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = rand_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\", rand_search.best_params_)\n",
    "print(\"\\nTuned Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c37743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8db4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
