{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2db4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c00b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f669204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Matthew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Matthew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.Defaults.stop_words -= {\"not\", \"do\"}\n",
    "from autocorrect import Speller\n",
    "nltk.download('words')\n",
    "import emoji\n",
    "import sqlite3\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import contractions\n",
    "nltk.download('wordnet')\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561059f",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c64396c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"IMDB_Movies_2021.db\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "table_name = \"REVIEWS\"\n",
    "\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc7536",
   "metadata": {},
   "source": [
    "# Drop duplicates and remove nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27604dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset = ['REVIEW','AUTHOR'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d812a",
   "metadata": {},
   "source": [
    "# Combine review and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf001935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIXED_REVIEW'] = df['REVIEW'] +df['TITLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d05229",
   "metadata": {},
   "source": [
    "# Simple preprocesing: lowercase, punctuation, emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82a80df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIXED_REVIEW'] = [review.lower() for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [re.sub(r'[^a-zA-Z\\s]', '', review) for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [re.sub(r'@\\w+', '', review) for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [re.sub(r'#\\w+', '', review) for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [re.sub(r'http\\S+|www\\S+|https\\S+', '', review) for review in df['FIXED_REVIEW']]\n",
    "df['FIXED_REVIEW'] = [emoji.demojize(review) for review in df['FIXED_REVIEW']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbc286",
   "metadata": {},
   "source": [
    "# Remove stop short and long words, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "466b3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('no')\n",
    "def sentiment(word):\n",
    "    blob = TextBlob(word)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    return np.abs(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "402c2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    text = contractions.fix(text)\n",
    "    words = text.split()    # Tokenize the text into words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    filtered_words = [word for word in filtered_words if len(word) > 2]\n",
    "    filtered_words = [word for word in filtered_words if len(word) < 8]\n",
    "    filtered_words = [word for word in filtered_words if sentiment(word) != 0 ]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96978f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIXED_REVIEW'] = df['FIXED_REVIEW'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c186bc",
   "metadata": {},
   "source": [
    "# Remove misspelt words (maybe replace with better method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cecbc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "setofwords = set(words.words())\n",
    "\n",
    "print(\"hello\" in setofwords)\n",
    "\n",
    "j = 0\n",
    "new_review = []\n",
    "\n",
    "for i in df['FIXED_REVIEW']:\n",
    "    words = word_tokenize(i)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word in setofwords:\n",
    "            new_words.append(word)\n",
    "    sentence_correct = ' '.join(new_words)        \n",
    "    new_review.append(sentence_correct)\n",
    "    #df['FIXED_REVIEW'][j] = sentence_correct\n",
    "    j+=1\n",
    "\n",
    "\n",
    "df['FIXED_REVIEW'] = new_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a138e5",
   "metadata": {},
   "source": [
    "# Add our target (ie: class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0030848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_race(row):\n",
    "    if row['RATING'] >= 7:\n",
    "        return 2\n",
    "    if row['RATING'] <= 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['CLASS'] = df.apply(label_race, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc910a43",
   "metadata": {},
   "source": [
    "# Add sentiment as column (can add more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "807aaf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_1(text):\n",
    "    return TextBlob(text).sentiment.polarity \n",
    "df['sentiment_1'] = df['FIXED_REVIEW'].apply(get_sentiment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32efd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)\n",
    "    compound_score = sentiment_score['compound']\n",
    "    \n",
    "    return compound_score\n",
    "\n",
    "def vader_class(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)\n",
    "    compound_score = sentiment_score['compound']\n",
    "    \n",
    "    if compound_score > 0.1:\n",
    "        sentiment = \"Positive\"\n",
    "    elif compound_score < -0.1:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Neutral\"\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ddc8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_sentiment'] = df['FIXED_REVIEW'].apply(vader_sentiment)\n",
    "df['vader_class'] = df['FIXED_REVIEW'].apply(vader_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242c44f",
   "metadata": {},
   "source": [
    "# Add a tokenized column for topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a6f8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7c5926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_review'] = df['FIXED_REVIEW'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ff2ce",
   "metadata": {},
   "source": [
    "# Now use LDA for topics, gives additional context (may need to optimise how many topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12d52915",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df['tokenized_review'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['tokenized_review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0d45584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, passes=20, alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95129f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = [lda_model.get_document_topics(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32d479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_matrix = []\n",
    "for dist in topic_distributions:\n",
    "    topic_vector = [0] * 10  # Number of topics (in this case 2)\n",
    "    for topic_id, prob in dist:\n",
    "        topic_vector[topic_id] = prob\n",
    "    topic_matrix.append(topic_vector)\n",
    "\n",
    "# Convert topic_matrix to a DataFrame for easy handling\n",
    "topic_df = pd.DataFrame(topic_matrix, columns=[f\"topic_{i}\" for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2fd3a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, topic_df], axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ee84b",
   "metadata": {},
   "source": [
    "# Now BOW with tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d457eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer(ngram_range = (1,2))\n",
    "bow = v.fit_transform(df.FIXED_REVIEW.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "596da57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = pd.DataFrame.sparse.from_spmatrix(bow, columns = v.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bc140126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, bow], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6618412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['ID','RATING','REVIEW','TITLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5712c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a55a36",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f773b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431be582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8a746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14aa5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510992c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5377cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04a585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94438fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c5792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc3bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb9b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
