{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c813d0",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2db4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c00b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f669204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.Defaults.stop_words -= {\"not\", \"do\"}\n",
    "from autocorrect import Speller\n",
    "nltk.download('words', quiet=True)\n",
    "import emoji\n",
    "import sqlite3\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import contractions\n",
    "nltk.download('wordnet', quiet=True)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from pprint import pprint\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561059f",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64396c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"IMDB_Movies_2021.db\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "table_name = \"REVIEWS\"\n",
    "\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc7536",
   "metadata": {},
   "source": [
    "# Drop duplicates and remove nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27604dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset = ['REVIEW','AUTHOR'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d812a",
   "metadata": {},
   "source": [
    "# Combine review and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf001935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIXED_REVIEW'] = df['REVIEW'] +df['TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b54a5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I don't get all the terrible reviews for this ...\n",
       "1       I cannot believe anyone could give this film l...\n",
       "2       Great White is not the worst way to spend 90 m...\n",
       "3       Great White is as basic of a killer shark film...\n",
       "4       Terrible story, dialogue and CGI. The film has...\n",
       "                              ...                        \n",
       "5420    It's master piece by Zack please part 2,3,4 al...\n",
       "5421    No words to describe. It's awesome. One of the...\n",
       "5422    Far better than previous one and better editin...\n",
       "5423    Why did the studio say no to this masterpiece?...\n",
       "5424    Overall Opinion-\\nAlthough the competitors Mar...\n",
       "Name: FIXED_REVIEW, Length: 5304, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FIXED_REVIEW']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d05229",
   "metadata": {},
   "source": [
    "# Simple preprocesing: lowercase, punctuation, emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a80df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned the text by using Regex\n",
    "df['FIXED_REVIEW'] = [review.lower() for review in df['FIXED_REVIEW']]   # Lowercase\n",
    "df['FIXED_REVIEW'] = [re.sub(r'[^a-zA-Z\\s]', '', review) for review in df['FIXED_REVIEW']]  # Remove punctuation and numbers\n",
    "df['FIXED_REVIEW'] = [re.sub(r'@\\w+', '', review) for review in df['FIXED_REVIEW']]   # Remove mentions\n",
    "df['FIXED_REVIEW'] = [re.sub(r'#\\w+', '', review) for review in df['FIXED_REVIEW']]   # Remove hashtags\n",
    "df['FIXED_REVIEW'] = [re.sub(r'http\\S+|www\\S+|https\\S+', '', review) for review in df['FIXED_REVIEW']]  # Remove URLS\n",
    "df['FIXED_REVIEW'] = [emoji.demojize(review) for review in df['FIXED_REVIEW']]    # Emoji to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d8733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i dont get all the terrible reviews for this m...\n",
       "1       i cannot believe anyone could give this film l...\n",
       "2       great white is not the worst way to spend  min...\n",
       "3       great white is as basic of a killer shark film...\n",
       "4       terrible story dialogue and cgi the film has a...\n",
       "                              ...                        \n",
       "5420    its master piece by zack please part  also man...\n",
       "5421    no words to describe its awesome one of the be...\n",
       "5422    far better than previous one and better editin...\n",
       "5423    why did the studio say no to this masterpiece ...\n",
       "5424    overall opinion\\nalthough the competitors marv...\n",
       "Name: FIXED_REVIEW, Length: 5304, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FIXED_REVIEW']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbc286",
   "metadata": {},
   "source": [
    "# Remove stop short and long words, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "466b3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('no')\n",
    "def sentiment(word):\n",
    "    blob = TextBlob(word)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    return np.abs(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "402c2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    text = contractions.fix(text)\n",
    "    words = text.split()    # Tokenize the text into words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    filtered_words = [word for word in filtered_words if len(word) >= 2]\n",
    "    filtered_words = [word for word in filtered_words if len(word) < 10]\n",
    "    filtered_words = [word for word in filtered_words if sentiment(word) != 0 ]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96978f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIXED_REVIEW'] = df['FIXED_REVIEW'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a864e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       terrible bad special worthy terrible good litt...\n",
       "1                                 less great exciting bad\n",
       "2       great worst wealthy victim great cheap great c...\n",
       "3       great everyday ordinary ok certain real bloody...\n",
       "4                  terrible wide first much much terrible\n",
       "                              ...                        \n",
       "5420                                                     \n",
       "5421                               awesome best fantastic\n",
       "5422                   far better previous better awesome\n",
       "5423                                  seriously mean epic\n",
       "5424    comic enjoy clear perfect strong previous clea...\n",
       "Name: FIXED_REVIEW, Length: 5304, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FIXED_REVIEW']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c186bc",
   "metadata": {},
   "source": [
    "# Remove misspelt words (maybe replace with better method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed8d740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller()\n",
    "df['FIXED_REVIEW'] = df['FIXED_REVIEW'].apply(spell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f74dbda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "setofwords = set(words.words())\n",
    "\n",
    "print(\"excited\" in setofwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cecbc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "new_review = []\n",
    "\n",
    "for i in df['FIXED_REVIEW']:\n",
    "    words = word_tokenize(i)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word in setofwords:\n",
    "            new_words.append(word)\n",
    "    sentence_correct = ' '.join(new_words)        \n",
    "    new_review.append(sentence_correct)\n",
    "    #df['FIXED_REVIEW'][j] = sentence_correct\n",
    "    j+=1\n",
    "\n",
    "\n",
    "df['FIXED_REVIEW'] = new_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4110b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    terrible bad special worthy terrible good litt...\n",
      "1                              less great exciting bad\n",
      "2    great worst wealthy victim great cheap great c...\n",
      "3    great everyday ordinary certain real bloody ki...\n",
      "4               terrible wide first much much terrible\n",
      "Name: FIXED_REVIEW, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['FIXED_REVIEW'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a138e5",
   "metadata": {},
   "source": [
    "# Add our target (ie: class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0030848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_race(row):\n",
    "    if row['RATING'] >= 7:\n",
    "        return 2\n",
    "    if row['RATING'] <= 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['CLASS'] = df.apply(label_race, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "991db7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    2191\n",
      "0    2014\n",
      "1    1099\n",
      "Name: CLASS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['CLASS'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc910a43",
   "metadata": {},
   "source": [
    "# Add sentiment as column (can add more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "807aaf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sentiment Score with TextBlob\n",
    "def get_sentiment_1(text):\n",
    "    return TextBlob(text).sentiment.polarity \n",
    "df['sentiment_1'] = df['FIXED_REVIEW'].apply(get_sentiment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32efd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)\n",
    "    compound_score = sentiment_score['compound']\n",
    "    \n",
    "    return compound_score\n",
    "\n",
    "def vader_class(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)\n",
    "    compound_score = sentiment_score['compound']\n",
    "    \n",
    "    if compound_score > 0.1:\n",
    "        sentiment = 2\n",
    "    elif compound_score < -0.1:\n",
    "        sentiment = 0\n",
    "    else:\n",
    "        sentiment = 1\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ddc8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_sentiment'] = df['FIXED_REVIEW'].apply(vader_sentiment)\n",
    "df['vader_class'] = df['FIXED_REVIEW'].apply(vader_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e273b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment_1  vader_sentiment  vader_class\n",
      "0    -0.299669          -0.8036            0\n",
      "1     0.058333           0.5412            2\n",
      "2     0.321807           0.9839            2\n",
      "3    -0.021337           0.9133            2\n",
      "4    -0.462500          -0.7351            0\n"
     ]
    }
   ],
   "source": [
    "print(df[['sentiment_1', 'vader_sentiment', 'vader_class']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242c44f",
   "metadata": {},
   "source": [
    "# Add a tokenized column for topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f8854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7c5926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_review'] = df['FIXED_REVIEW'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db70b4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [terrible, bad, special, worthy, terrible, goo...\n",
      "1                         [less, great, exciting, bad]\n",
      "2    [great, worst, wealthy, victim, great, cheap, ...\n",
      "3    [great, everyday, ordinary, certain, real, blo...\n",
      "4        [terrible, wide, first, much, much, terrible]\n",
      "Name: tokenized_review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['tokenized_review'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ff2ce",
   "metadata": {},
   "source": [
    "# Now use LDA for topics, gives additional context (may need to optimise how many topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d8efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12d52915",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df['tokenized_review'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['tokenized_review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d45584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics=20\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=20, alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95129f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = [lda_model.get_document_topics(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32d479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_matrix = []\n",
    "for dist in topic_distributions:\n",
    "    topic_vector = [0] * num_topics  # Number of topics (in this case 2)\n",
    "    for topic_id, prob in dist:\n",
    "        topic_vector[topic_id] = prob\n",
    "    topic_matrix.append(topic_vector)\n",
    "\n",
    "# Convert topic_matrix to a DataFrame for easy handling\n",
    "topic_df = pd.DataFrame(topic_matrix, columns=[f\"topic_{i+1}\" for i in range(num_topics)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fd3a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, topic_df], axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7e891d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>RATING</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>FIXED_REVIEW</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>vader_class</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I don't get all the terrible reviews for this ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>margarida-44311</td>\n",
       "      <td>Not Bad\\n</td>\n",
       "      <td>terrible bad special worthy terrible good litt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.299669</td>\n",
       "      <td>-0.8036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I cannot believe anyone could give this film l...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>joemay-2</td>\n",
       "      <td>What are all the bad reviews about is it a wo...</td>\n",
       "      <td>less great exciting bad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.5412</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>0.013186</td>\n",
       "      <td>0.203828</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.013305</td>\n",
       "      <td>0.016907</td>\n",
       "      <td>0.375350</td>\n",
       "      <td>0.012423</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Great White is not the worst way to spend 90 m...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nebk</td>\n",
       "      <td>Great White=Jaws Lite\\n</td>\n",
       "      <td>great worst wealthy victim great cheap great c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321807</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055826</td>\n",
       "      <td>0.033114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112409</td>\n",
       "      <td>0.304684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Great White is as basic of a killer shark film...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>kuarinofu</td>\n",
       "      <td>Bare-bones killer shark film\\n</td>\n",
       "      <td>great everyday ordinary certain real bloody ki...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021337</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096944</td>\n",
       "      <td>0.110776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Terrible story, dialogue and CGI. The film has...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Horror_Flick_Fanatic</td>\n",
       "      <td>Terrible story, dialogue, and CGI\\n</td>\n",
       "      <td>terrible wide first much much terrible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.462500</td>\n",
       "      <td>-0.7351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012546</td>\n",
       "      <td>0.336880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.011222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                             REVIEW  RATING  \\\n",
       "0  1.0  I don't get all the terrible reviews for this ...     5.0   \n",
       "1  2.0  I cannot believe anyone could give this film l...     8.0   \n",
       "2  3.0  Great White is not the worst way to spend 90 m...     4.0   \n",
       "3  4.0  Great White is as basic of a killer shark film...     4.0   \n",
       "4  5.0  Terrible story, dialogue and CGI. The film has...     4.0   \n",
       "\n",
       "                 AUTHOR                                              TITLE  \\\n",
       "0       margarida-44311                                          Not Bad\\n   \n",
       "1              joemay-2   What are all the bad reviews about is it a wo...   \n",
       "2                  nebk                            Great White=Jaws Lite\\n   \n",
       "3             kuarinofu                     Bare-bones killer shark film\\n   \n",
       "4  Horror_Flick_Fanatic                Terrible story, dialogue, and CGI\\n   \n",
       "\n",
       "                                        FIXED_REVIEW  CLASS  sentiment_1  \\\n",
       "0  terrible bad special worthy terrible good litt...    1.0    -0.299669   \n",
       "1                            less great exciting bad    2.0     0.058333   \n",
       "2  great worst wealthy victim great cheap great c...    1.0     0.321807   \n",
       "3  great everyday ordinary certain real bloody ki...    1.0    -0.021337   \n",
       "4             terrible wide first much much terrible    1.0    -0.462500   \n",
       "\n",
       "   vader_sentiment  vader_class  ...  topic_11  topic_12  topic_13  topic_14  \\\n",
       "0          -0.8036          0.0  ...  0.000000  0.000000  0.476151  0.000000   \n",
       "1           0.5412          2.0  ...  0.011021  0.013186  0.203828  0.012336   \n",
       "2           0.9839          2.0  ...  0.000000  0.055826  0.033114  0.000000   \n",
       "3           0.9133          2.0  ...  0.000000  0.000000  0.010425  0.000000   \n",
       "4          -0.7351          0.0  ...  0.000000  0.000000  0.282749  0.000000   \n",
       "\n",
       "   topic_15  topic_16  topic_17  topic_18  topic_19  topic_20  \n",
       "0  0.000000  0.000000  0.000000  0.143583  0.000000  0.000000  \n",
       "1  0.013305  0.016907  0.375350  0.012423  0.014082  0.015123  \n",
       "2  0.000000  0.112409  0.304684  0.000000  0.057025  0.000000  \n",
       "3  0.096944  0.110776  0.000000  0.000000  0.000000  0.207216  \n",
       "4  0.000000  0.012546  0.336880  0.000000  0.010451  0.011222  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ee84b",
   "metadata": {},
   "source": [
    "# Now BOW with tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d457eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "596da57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['FIXED_REVIEW'])\n",
    "\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(\n",
    "    tfidf_matrix,\n",
    "    columns=tfidf_vectorizer.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc140126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6618412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID', 'RATING', 'REVIEW', 'TITLE'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5712c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5c490fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5187, 5027)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a55a36",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f773b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7df82",
   "metadata": {},
   "source": [
    "# Using the data in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aff3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['CLASS', 'AUTHOR','FIXED_REVIEW','tokenized_review'])\n",
    "y = df['CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0c41f",
   "metadata": {},
   "source": [
    "# Feature Selection: RFE Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97b8a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Random Forest): ['sentiment_1', 'vader_sentiment', 'vader_class', 'topic_13', 'topic_10', 'topic_6', 'topic_17', 'topic_2', 'topic_16', 'waste', 'topic_19', 'topic_1', 'topic_20', 'topic_12', 'topic_18', 'great', 'topic_3', 'topic_15', 'topic_14', 'topic_11', 'topic_7', 'good', 'bad', 'topic_4', 'topic_5', 'topic_8', 'boring', 'really', 'topic_9', 'terrible', 'worst', 'better', 'much', 'amazing', 'love', 'perfect', 'awful', 'funny', 'best', 'little', 'real', 'horrible', 'beautiful', 'new', 'first', 'action', 'poor', 'many', 'fun', 'kind', 'pretty', 'decent', 'worth', 'long', 'half', 'excellent', 'main', 'mean', 'whole', 'slow', 'average', 'black', 'mess', 'sure', 'nice', 'stupid', 'enjoy', 'fly', 'worse', 'young', 'brilliant', 'less', 'original', 'enjoyable', 'old', 'right', 'hard', 'high', 'wonderful', 'laugh', 'wasted', 'poorly', 'least', 'wrong', 'true', 'far', 'fine', 'dull', 'fantastic', 'weak', 'pointless', 'really good', 'dumb', 'mediocre', 'powerful', 'highly', 'forced', 'bad bad', 'rose', 'hate', 'superb', 'past', 'sound', 'special', 'weird', 'complete', 'full', 'negative', 'cool', 'annoying', 'good good', 'flat', 'cheap', 'single', 'sorry', 'much better', 'awesome', 'certainly', 'typical', 'top', 'important', 'huge', 'bland', 'classic', 'worthy', 'easy', 'mostly', 'seriously', 'straight', 'super', 'easily', 'live', 'sad', 'extremely', 'good great', 'exactly', 'sadly', 'good bad', 'game', 'strong', 'able', 'lame', 'subject', 'first half', 'bad good', 'certain', 'scary', 'plain', 'honest', 'clearly', 'difficult', 'cute', 'honestly', 'badly', 'military', 'evil', 'lazy', 'light', 'major', 'small', 'realistic', 'silly', 'flawed', 'modern', 'unique', 'good really', 'quickly', 'excited', 'favorite', 'engaging', 'cheese', 'win', 'social', 'usual', 'behind', 'early', 'positive', 'dead', 'great great', 'nearly', 'brutal', 'perfectly', 'near', 'really bad', 'crazy', 'common', 'usually', 'spent', 'dark', 'general', 'missing', 'due', 'fit', 'glad', 'tired', 'serious', 'good first', 'clear', 'fair', 'pretty good', 'strange', 'late', 'fake', 'awkward', 'raw', 'drag', 'adult', 'talented', 'crap', 'random', 'happy', 'sweet', 'absolute', 'afraid', 'illegal', 'thanks', 'good better', 'normal', 'ill', 'clever', 'great good', 'slow boring', 'painful', 'really great', 'touching', 'fast', 'shallow', 'barely', 'great really', 'creative', 'familiar', 'creepy', 'smart', 'hilarious', 'criminal', 'filled', 'tedious', 'laughable', 'loud', 'exciting', 'odd', 'becoming', 'hot', 'free', 'fairly', 'cold', 'broken', 'terribly', 'really really', 'wow', 'fail', 'pure', 'loose', 'victim', 'higher', 'trouble', 'great bad', 'hidden', 'gory', 'excuse', 'bloody', 'epic', 'action action', 'atrocious', 'previous', 'much much', 'intense', 'pathetic', 'ready', 'first good', 'confused', 'unable', 'mad', 'comic', 'good much', 'slightly', 'desperate', 'sick', 'better good', 'dramatic', 'secret', 'long really', 'sexual', 'genuine', 'minus', 'exact', 'really love', 'dry', 'good action', 'great action', 'nicely', 'painfully', 'tense', 'charming', 'stunning', 'lucky', 'bad better', 'thin', 'much good', 'limited', 'large', 'bad really', 'messy', 'action good', 'love love', 'fresh', 'alien', 'tough', 'winning', 'pretty much', 'idiot', 'gorgeous', 'normally', 'lovely', 'half good', 'green', 'terrible bad', 'tragic', 'complex', 'better much', 'good old', 'best good', 'relevant', 'good kind', 'heavily', 'worth much', 'heavy', 'shocking', 'rare', 'angry', 'adequate', 'amateur', 'destroy', 'alive', 'cultural', 'boring boring', 'absurd', 'bad great', 'mental', 'apparent', 'main really', 'latest', 'effective', 'really new', 'little great', 'many better', 'better better', 'action great', 'rich', 'genuinely', 'really main', 'pleasant', 'childish', 'great better', 'rarely', 'first many', 'subtle', 'empty', 'direct', 'good fun', 'bad worst', 'trapped', 'great much', 'famous', 'really much', 'promising', 'thrilling', 'first really', 'amazing amazing', 'really sure', 'funny bad', 'long boring', 'stellar', 'really whole', 'much great', 'gripping', 'insane', 'artistic', 'really long', 'minor', 'ordinary', 'much really', 'extreme', 'good pretty', 'complaint', 'little little', 'funny good', 'closed', 'wet', 'dreadful', 'accurate', 'safe', 'good decent', 'unlikely', 'black black', 'nice good', 'quick', 'much main', 'great special', 'bizarre', 'waste bad', 'great worth', 'violent', 'really kind', 'sure good', 'bad waste', 'love good', 'false', 'wide', 'many great', 'best best', 'little really', 'slowly', 'action really', 'happily', 'liable', 'horrific', 'many bad', 'little bad', 'awfully', 'good mean', 'memorable', 'many many', 'magic', 'decent good', 'sharp', 'pity', 'good little', 'bad pretty', 'wise', 'drunk', 'sound good', 'much love', 'cleverly', 'sure much', 'many good', 'wrong dead', 'much wrong', 'smile', 'less really', 'great black', 'worth good', 'love action', 'intimate', 'seasoned', 'kind really', 'first bad', 'much many', 'grand', 'better many', 'great terrible', 'authentic', 'stale', 'little boring', 'real good', 'good long', 'popular', 'bad action', 'great waste', 'good real', 'great boring', 'great amazing', 'gay', 'sinister', 'action bad', 'joy', 'mindless', 'older', 'first fun', 'original good', 'endless', 'real worth', 'vaguely', 'action kind', 'distant', 'good black', 'good half', 'failure', 'down', 'sticker', 'unknown', 'pretty poor', 'bad little', 'useless', 'amazing much', 'pretty bad', 'love much', 'many first', 'boring good', 'good worth', 'mediocre action', 'naive', 'much new', 'really best', 'near good', 'real real', 'great weak', 'dangerous', 'half half', 'great first', 'first great', 'slow slow', 'really pretty', 'willing', 'devoid', 'little good', 'bad hate', 'boring great', 'old bad', 'padding', 'married', 'many really', 'real really', 'bright', 'great little', 'hardly', 'boring better', 'suitable', 'military military', 'evident', 'bad much', 'action much', 'less less', 'fun fun', 'good many', 'huge good', 'success', 'good wrong', 'good main', 'tight', 'much hate', 'real bad', 'brilliant worth', 'little much', 'funny laugh', 'slight', 'mildly', 'really enjoy', 'spoof', 'center', 'far better', 'splendid', 'much less', 'surely', 'rank', 'best worst', 'good original', 'good nice', 'good slow', 'bad special', 'first first', 'bad worth', 'live best', 'precious', 'whole much', 'mainly', 'really first', 'wild', 'competent', 'action pretty', 'better first', 'brightly', 'forced much', 'new better', 'lousy', 'main main', 'main good', 'old good', 'better bad', 'fabulous', 'whole best', 'titular', 'really better', 'really real', 'love great', 'cool cool', 'love main', 'good love', 'new good', 'great long', 'clean', 'really strong', 'least really', 'past enjoy', 'best much', 'much action', 'new bad', 'whole really', 'sure great', 'good terrible', 'idiotic', 'ugly', 'bad less', 'shaky', 'capable', 'good perfect', 'old great', 'mean really', 'love hate', 'really negative', 'abrupt', 'loosely', 'enjoy good', 'bad decent', 'firstly', 'better really', 'waste better', 'bad enjoy', 'funny real', 'good boring', 'kind bad', 'aware', 'useful', 'captive', 'guilty', 'half enjoy', 'kind first', 'inspiring', 'waste good', 'full good', 'blatant', 'frequent', 'profound', 'good new', 'poor really', 'cow', 'ideal', 'pretty decent', 'long good', 'weird sexual', 'clumsy', 'first better', 'bad real', 'boring first', 'much real', 'curious', 'love black', 'stupid fun', 'pregnant', 'long slow', 'much little', 'natural', 'many little', 'great love', 'needless', 'good annoying', 'kind much', 'really boring', 'great horrible', 'fly good', 'pretty sure', 'generally', 'good flat', 'better new', 'nasty', 'cheese bad', 'early new', 'boring old', 'riveting', 'lately', 'warm', 'gruesome', 'better great', 'mean good', 'good poorly', 'mess better', 'main first', 'love wrong', 'directly', 'super bad', 'really many', 'really certainly', 'strange really', 'little better', 'little right', 'top great', 'rough', 'decent action', 'really hard', 'funny funny', 'long long', 'iconic', 'little slow', 'credible', 'love long', 'full boring', 'great cool', 'great wasted', 'good best', 'worst waste', 'rewarding', 'really exciting', 'great mean', 'masterful', 'better true', 'much slow', 'complete waste', 'mess bad', 'bad silly', 'far good', 'great slow', 'bad top', 'great dull', 'sloppy', 'long great', 'logical', 'alive good', 'better funny', 'grief', 'uneven', 'great classic', 'amusing', 'dull boring', 'worst far', 'sincere', 'great main', 'fantastic good', 'laugh good', 'legendary', 'fluff', 'wasted worst', 'really nice', 'best sure', 'amazing great', 'good laugh', 'powerful good', 'action love', 'great wrong', 'bad many', 'better best', 'waste much', 'really poor', 'good mediocre', 'funny sure', 'strongly', 'slow little', 'first best', 'new old', 'flawless', 'boring really', 'first decent', 'greater', 'worst worst', 'straight good', 'right wrong', 'laugh loud', 'really slow', 'long better', 'poor bad', 'chilling', 'fun original', 'gifted', 'half boring', 'much right', 'hot mess', 'mediocre best', 'decent slow', 'really little', 'laugh many', 'love live', 'pale', 'minimal', 'worth really', 'many hard', 'beautiful much', 'decent really', 'crushed', 'bold', 'boring action', 'great fair', 'unusual', 'hollow', 'worth whole', 'bad funny', 'mature', 'great mediocre', 'hard great', 'poor poor', 'bad long', 'little action', 'mean great', 'harder', 'original great', 'really terrible', 'legal', 'mild', 'effective good', 'good easily', 'bad dull', 'grey', 'young good', 'sad true', 'good least', 'really full', 'bad whole', 'great fantastic', 'worth better', 'young great', 'good awfully', 'action fun', 'nice much', 'black really', 'good young', 'cool really', 'everyday', 'sorry love', 'good funny', 'amazing good', 'new amazing', 'scary laughable', 'fine good', 'boring bad', 'little sure', 'excessive', 'bad boring', 'plain bad', 'original better', 'true first', 'action best', 'whole great', 'insulting', 'great best', 'carefully', 'half really', 'good intense', 'harsh', 'action slow', 'bad flat', 'stumble', 'amazing really', 'average action', 'slow waste', 'whole kind', 'really funny', 'funny kind', 'good honest', 'specially', 'easily good', 'awful whole', 'cruel', 'boring real', 'usual good', 'mentally', 'new exciting', 'really action', 'half first', 'whole whole', 'good waste', 'better waste', 'available', 'good poor', 'addicted', 'love small', 'love best', 'pure pure', 'wrong first', 'black right', 'friendly', 'right really', 'wasted bad', 'really hate', 'pretty best', 'first worse', 'secretly', 'base', 'fly alien', 'nice great', 'elegant', 'worst wasted', 'heroic', 'great funny', 'dirty', 'bad difficult', 'whole strong', 'slow engaging', 'better loose', 'bad perfectly', 'goofy', 'loving', 'terrible pointless', 'good high', 'good far', 'typical action', 'flat boring', 'best great', 'old old', 'worth best', 'mean stupid', 'wisely', 'poor action', 'wrong great', 'waste great', 'wrong really', 'much terribly', 'forced good', 'evil good', 'many wrong', 'new great', 'miserably', 'great many', 'wasted waste', 'long worth', 'funny free', 'wrong much', 'sure love', 'many black', 'original new', 'sober', 'sure main', 'love little', 'original little', 'little many', 'seriously bad', 'bad least', 'action better', 'military game', 'action boring', 'elaborate', 'love really', 'better dull', 'active', 'excellent beautiful', 'young adult', 'nicely good', 'love many', 'first pretty', 'slow bad', 'wonderful good', 'canal', 'worthless', 'brave', 'casually', 'beloved', 'slow worth', 'seriously love', 'main many', 'early half', 'flashy', 'worth love', 'many boring', 'much pretty', 'much sure', 'average really', 'good worst', 'excited love', 'magically', 'really cool', 'greatly', 'fun good', 'great original', 'smooth', 'main better', 'right good', 'terrible really', 'skeptical', 'great decent', 'high high', 'really less', 'long first', 'good sure', 'right right', 'sexy', 'golden', 'new new', 'real dramatic', 'anger', 'first mean', 'much half', 'arrest', 'good hard', 'raw real', 'action bland', 'sad right', 'horrible little', 'little wrong', 'whole black', 'love waste', 'better boring', 'boring wasted', 'dead really', 'bad poorly', 'slight worth', 'bad main', 'whole beautiful', 'worst first', 'sincere beautiful', 'fun really', 'true better', 'worth easy', 'great favorite', 'little worth', 'true evil', 'pretty great', 'high action', 'randomly', 'pretty cool', 'hard black', 'whole waste', 'really waste', 'great sadly', 'funny mostly', 'really right', 'redundant', 'many whole', 'fine many', 'boring badly', 'socially', 'black kind', 'jail', 'new original', 'mean bad', 'full better', 'perfect bad', 'criminal bad', 'least much', 'good whole', 'tiresome', 'best far', 'bad right', 'decent worth', 'boring hard', 'original original', 'high really', 'funny scary', 'new pretty', 'good usual', 'mostly really', 'boring much', 'action pointless', 'slow first', 'twisted', 'fairly first', 'terrible good', 'bad spent', 'real pretty', 'forced really', 'best past', 'sure action', 'fly fly', 'little perfect', 'faint', 'kind hard', 'full action', 'seamless', 'much certainly', 'amazing true', 'better mean', 'annoying good', 'juvenile', 'boring mean', 'fun laugh', 'good special', 'much whole', 'sound bad', 'full negative', 'real first', 'good accurate', 'least less', 'enjoy bad', 'superior', 'little first', 'beautiful really', 'right long', 'great sad', 'much perfect', 'healthy', 'wasted boring', 'whole bad', 'sensitive', 'real enjoyable', 'wrong fun', 'fantastic honestly', 'love mean', 'round', 'vague', 'better sure', 'fine great', 'stylish', 'fun funny', 'true really', 'vibrant', 'less decent', 'grim', 'kind real', 'old action', 'typically', 'many cheap', 'fun love', 'good ordinary', 'good horrible', 'better pretty', 'modest', 'main annoying', 'worth worth', 'whole boring', 'bad fun', 'horribly', 'gentle', 'best love', 'whole hard', 'real action', 'little less', 'many fun', 'really small', 'better original', 'new young', 'great wonderful', 'less great', 'boring easily', 'real sad', 'little nice', 'good clear', 'right first', 'love first', 'shy', 'right mean', 'fantastic funny', 'main awful', 'good fly', 'new first', 'fun kind', 'hard really', 'waste fake', 'old original', 'wrong action', 'good right', 'wildly', 'action decent', 'black hard', 'better worse', 'huge bad', 'great loud', 'farce', 'less action', 'best true', 'really young', 'bad worse', 'good extremely', 'honest really', 'sure better', 'slow love', 'waste waste', 'calm', 'far bad', 'honest good', 'right many', 'huge really', 'black real', 'old new', 'slow really', 'poorly bad', 'better spent', 'half decent', 'hate far', 'perfect really', 'new far', 'edgy', 'preach', 'black long', 'really brilliant', 'excited great', 'good true', 'action original', 'purely', 'good weird', 'better main', 'really worth', 'slow main', 'much fun', 'certainly great', 'bad fly', 'enjoyable many', 'much old', 'menacing', 'original classic', 'clear love', 'action many', 'enjoy new', 'pretty awful', 'hard real', 'better love', 'plainly', 'sure sure', 'annoying boring', 'worse higher', 'great real', 'wan', 'humorous', 'really late', 'much single', 'many original', 'main little', 'stupidity', 'really quickly', 'game love', 'fake love', 'powerful bad', 'narrow', 'beautiful wonderful', 'usual bad', 'easy nice', 'bad hilarious', 'really half', 'mean best', 'much bad', 'really pity', 'whole little', 'funny thanks', 'pretty extremely', 'amazingly', 'first much', 'steady', 'extremely really', 'mean mean', 'casual', 'good scary', 'good fair', 'many bland', 'engaging good', 'wacky', 'unfair', 'beautiful beautiful', 'appealing', 'old kind', 'colorful', 'great poor', 'real comic', 'waste really', 'great enjoy', 'inventive', 'main pretty', 'serious serious', 'bad high', 'good game', 'imitation', 'special worth', 'real main', 'perfect perfect', 'bad best', 'much far', 'light true', 'bad poor', 'limp', 'sure worse', 'due poor', 'cheap laugh', 'good evil', 'live little', 'love super', 'lonely', 'awesome good', 'much usual', 'best first', 'gimmick', 'action certainly', 'right best', 'fun worth', 'funny whole', 'naturally', 'really fine', 'hate better', 'satisfied', 'really sad', 'good top', 'worth average', 'original funny', 'appalling', 'real best', 'precise', 'worth great', 'main hidden', 'great laugh', 'good serious', 'poor good', 'great fine', 'whole less', 'newly', 'kind flat', 'awesome strange', 'great fun', 'gladly', 'excited good', 'pretty boring', 'mean much', 'drag good', 'kind love', 'great crazy', 'far worse', 'crisp', 'dull dull', 'really intense', 'first modern', 'sure little', 'bad new', 'real love', 'fit perfectly', 'best original', 'original really', 'much average', 'poorly poorly', 'boring new', 'better long', 'detailed', 'free much', 'first long', 'really high', 'true worth', 'unique sincere', 'action dumb', 'funny usual', 'old nice', 'awful complete', 'super excited', 'able first', 'enjoy funny', 'great sound', 'weird creepy', 'live really', 'great perfect', 'best long', 'shady', 'slightly better', 'much worst', 'enjoy far', 'better half', 'action crap', 'less good', 'laugh better', 'real far', 'black good', 'stiff', 'true good', 'half fun', 'fantastic slow', 'far real', 'vulgar', 'bad fairly', 'far seriously', 'wow bad', 'illegal illegal', 'handsome', 'favorite really', 'laugh smile', 'really painful', 'bad love', 'best better', 'funny long', 'new boring', 'choppy', 'better right', 'bad mediocre', 'worst slow', 'really horrible', 'genuine really', 'really fun', 'soft', 'many best', 'busy', 'great awful', 'poetic', 'hard good', 'whole awful', 'seriously old', 'kind little', 'first worst', 'great far', 'enjoy action', 'small really', 'innocent', 'good drag', 'main great', 'love excited', 'sure bad', 'great amateur', 'bad mean', 'whole love', 'young first', 'special good', 'serious happy', 'good absolute', 'really common', 'classic love', 'first right', 'terrible terrible', 'much first', 'whole pure', 'least great', 'good smooth', 'average enjoy', 'funny love', 'worse funny', 'realistic realistic', 'victim good', 'little enjoyable', 'really mean', 'worse good', 'skilled', 'fun great', 'new action', 'fit military', 'much boring', 'selfish', 'much terrible', 'love high', 'really talented', 'best really', 'much honest', 'really weird', 'powerful great', 'many worth', 'really top', 'really hot', 'clear much', 'bad complete', 'kind better', 'little love', 'sorry good', 'insecure', 'many poorly', 'coherent', 'love laugh', 'new straight', 'enjoyable good', 'secondary', 'high love', 'excellent least', 'pretty nice', 'exact fly', 'pretty fun', 'good super', 'beautiful good', 'little long', 'less awful', 'horrible good', 'cheap scary', 'miserable', 'excellent new', 'first wow', 'black great', 'remote', 'easily better', 'right enjoy', 'live original', 'poor great', 'little stupid', 'bad slow', 'honestly better', 'mean real', 'wrong seriously', 'enjoy great', 'bad beautiful', 'enjoy half', 'deadly', 'many fake', 'usually kind', 'love real', 'long much', 'little unfair', 'right previous', 'black afraid', 'decent pretty', 'fast action', 'worth nice', 'much mostly', 'bootleg', 'half many', 'witty', 'little tired', 'bad terrible', 'much least', 'true love', 'great sure', 'lyric', 'many real', 'wrong good', 'brilliant little', 'evil mean', 'really excited', 'poorly much', 'good subject', 'better enjoy', 'best funny', 'fun many', 'corrupt', 'highly full', 'first black', 'far much', 'long kind', 'fun action', 'extremely negative', 'good straight', 'weak good', 'much mess', 'half worst', 'top good', 'bad extremely', 'good beautiful', 'cheese boring', 'much cool', 'funny better', 'welcome', 'far original', 'good enjoy', 'good lazy', 'enjoy enjoy', 'far best', 'awful poor', 'sadly really', 'true action', 'typical good', 'worst bad', 'better far', 'weird much', 'anxious', 'great awesome', 'high boring', 'fine much', 'little fine', 'blind', 'much important', 'hate good', 'strong first', 'noble', 'perfect long', 'primarily', 'plausible', 'high mostly', 'decent best', 'seriously best', 'sure wonderful', 'pretty bland', 'right whole', 'first cute', 'exhausted', 'behind good', 'bad forced', 'mundane', 'good less', 'good sad', 'sorry bad', 'hate great', 'clumsy much', 'green light', 'love terrible', 'boring easy', 'hard hard', 'best hate', 'negative really', 'due really', 'largely', 'good fine', 'real lightly', 'better important', 'favorite good', 'action lazy', 'bad sad', 'important good', 'right bad', 'good enjoyable', 'right great', 'good powerful', 'old better', 'secret behind', 'high bad', 'gripping good', 'much dead', 'real original', 'perfect little', 'raw love', 'good silly', 'favorite action', 'first angry', 'dumb dumb', 'ambitious', 'better kind', 'least decent', 'really beautiful', 'much wonderful', 'excited favorite', 'wasted high', 'bad thrilling', 'little old', 'enjoy much', 'really highly', 'action mediocre', 'extremely many', 'first kind', 'waste dull', 'much worse', 'clearly action', 'bad enjoyable', 'poorly good', 'fine pretty', 'fine fine', 'forced painfully', 'evil dead', 'quickly becoming', 'waste boring', 'scary great', 'full beautiful', 'best half', 'action single', 'main decent', 'important black', 'familiar good', 'less main', 'long real', 'old young', 'funny great', 'actively', 'old older', 'glad good', 'previous good', 'boring dull', 'pretty weak', 'bad awesome', 'pretty fair', 'missing good', 'really wrong', 'mean better', 'fly really', 'new main', 'high first', 'awesome better', 'powerful old', 'love pretty', 'enjoy worth', 'bitter', 'good usually', 'nice worth', 'scary usual', 'top really', 'new much', 'logically', 'much best', 'young young', 'fast really', 'hard old', 'really quick', 'high much', 'lame action', 'silly fun', 'real kind', 'family', 'sadly good', 'waste crap', 'kind enjoy', 'least action', 'angry right', 'bad military', 'full great', 'first boring', 'action special', 'little secret', 'real hate', 'awful really', 'real black', 'true dark', 'slick', 'flat real', 'generally love', 'half long', 'best boring', 'boring sure', 'original full', 'love less', 'safely', 'worse stupid', 'many negative', 'remotely', 'sure really', 'true true', 'new real', 'random poor', 'first annoying', 'action comic', 'typical best', 'ashamed', 'far far', 'good clearly', 'much fine', 'black mean', 'nearly adult', 'slow late', 'game horrible', 'cheap original', 'whole good', 'light mean', 'hugely', 'whole new', 'good rose', 'infamous', 'new mean', 'fly high', 'long tired', 'kind mad', 'single good', 'mean many', 'great quickly', 'small fine', 'flat great', 'best bad', 'good dumb', 'amazing sure', 'really light', 'real cruel', 'full bad', 'awkwardly', 'hard much', 'original bad', 'really perfect', 'previous better', 'terrible action', 'main less', 'first pure', 'casual really', 'beautiful amazing', 'new awful', 'nominally', 'worse waste', 'action amazing', 'far pretty', 'good important', 'first main', 'waste awful', 'fine wrong', 'many kind', 'waste free', 'exactly real', 'fast many', 'amazing slightly', 'great small', 'light good', 'true little', 'many much', 'single real', 'worst general', 'bad certainly', 'nice fun', 'less half', 'boring long', 'first able', 'easy really', 'long new', 'fun enjoy', 'love whole', 'boring terrible', 'boring love', 'good flawed', 'long beautiful', 'right boring', 'expensive', 'atrocious bad', 'easy high', 'much classic', 'awful good', 'best worth', 'fly little', 'least kind', 'worth bad', 'fantastic best', 'horrible great', 'good lovely', 'mean boring', 'action ill', 'love original', 'fun little', 'far trapped', 'better average', 'flawed good', 'favorite best', 'gory fun', 'great poorly', 'first wrong', 'action funny', 'less little', 'great half', 'action first', 'scary wrong', 'spent really', 'laugh love', 'oddly', 'awesome difficult', 'fairly bad', 'excuse good', 'game really', 'great full', 'kind half', 'magical', 'sad waste', 'first love', 'mean wrong', 'original much', 'pointless really', 'live action', 'old boring', 'long whole', 'smart really', 'barely really', 'old super', 'fun favorite', 'sermon', 'fun boring', 'young old', 'excited real', 'action right', 'aged', 'original nice', 'whole mean', 'average great', 'best cool', 'great beautiful', 'boring kind', 'typical many', 'love horrible', 'fast mean', 'action wrong', 'dumb bad', 'awful worst', 'really laugh', 'lifelong', 'military much', 'action cool', 'strong good', 'usual really', 'least terrible', 'true black', 'really fit', 'mean first', 'funny original', 'good fake', 'far exactly', 'old fun', 'seriously enjoyable', 'bad seriously', 'action new', 'really classic', 'nearly happy', 'huge much', 'good major', 'best mess', 'honestly good', 'action poorly', 'love fun', 'fair good', 'relevant important', 'full best', 'special right', 'fine better', 'worse new', 'sure real', 'mighty', 'rarely bad', 'enjoying', 'fantastic really', 'far long', 'bad amazing', 'stupid good', 'really special', 'little hard', 'unhappy', 'slow action', 'excellent really', 'tired really', 'kind old', 'first awful', 'good badly', 'creative great', 'good wow', 'crap good', 'much huge', 'true worse', 'good actively', 'bad sure', 'good charming', 'original poor', 'fine worth', 'fly excellent', 'usual little', 'really least', 'love kind', 'action hard', 'first near', 'excellent slow', 'slightly much', 'annoying funny', 'fair really', 'due little', 'strangely', 'better certainly', 'first sure', 'lazy better', 'brilliant beautiful', 'cutting', 'careful', 'enjoy long', 'distinct', 'worst worse', 'new alive', 'fake top', 'able enjoy', 'beautiful little', 'typical decent', 'worst great', 'real least', 'fun cute', 'love worth', 'much tough', 'boring flat', 'boring worst', 'false better', 'success first', 'weak really', 'dull full', 'dead best', 'honest much', 'random evil', 'partially', 'strong real', 'amazing bad', 'fitting', 'great kind', 'main important', 'boring cheese', 'true certainly', 'little true', 'far perfect', 'awful awful', 'typical high', 'original first', 'pointless boring', 'boring cheap', 'action little', 'real win', 'worth least', 'funny weird', 'boring black', 'seriously sound', 'fast worth', 'true mean', 'great mess', 'extreme action', 'confident', 'hate bad', 'really scary', 'major missing', 'seriously much', 'cheese good', 'hilarious bad', 'fun fine', 'boring waste', 'decent great', 'action main', 'good worse', 'much complete', 'new fly', 'great clearly', 'good crap', 'excellent good', 'main much', 'military real', 'good quick', 'full near', 'huge love', 'love favorite', 'bad game', 'right near', 'ready love', 'real nice', 'movable', 'best many', 'awful boring', 'little top', 'bad lame', 'easily real', 'great true', 'good win', 'outdated', 'lame weak', 'awful bad', 'serious light', 'many far', 'pretty ideal', 'really mental', 'clean ready', 'broken love', 'better terrible', 'great strong', 'good fresh', 'love far', 'least good', 'baseless', 'amazing worth', 'stupid waste', 'bad usual', 'really sound', 'mean new', 'exactly little', 'boring original', 'less least']\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=27, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "num_feature = 2000\n",
    "top_features_rf = [X.columns[i] for i in indices[:num_feature]]\n",
    "print(f\"Selected Features (Random Forest): {top_features_rf}\")\n",
    "\n",
    "X_selected = X[top_features_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f5051bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5187 entries, 0 to 5186\n",
      "Columns: 2000 entries, sentiment_1 to less least\n",
      "dtypes: Sparse[float64, 0](1977), float64(23)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_selected.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175fbf7",
   "metadata": {},
   "source": [
    "# PCA: Dimensionality Reduction\n",
    "\n",
    "## Again need to find optimum k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a05f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_scaled = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e69426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ec2c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=100\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_pca = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(n_components)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4999d180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5187 entries, 0 to 5186\n",
      "Data columns (total 100 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PC1     5187 non-null   float64\n",
      " 1   PC2     5187 non-null   float64\n",
      " 2   PC3     5187 non-null   float64\n",
      " 3   PC4     5187 non-null   float64\n",
      " 4   PC5     5187 non-null   float64\n",
      " 5   PC6     5187 non-null   float64\n",
      " 6   PC7     5187 non-null   float64\n",
      " 7   PC8     5187 non-null   float64\n",
      " 8   PC9     5187 non-null   float64\n",
      " 9   PC10    5187 non-null   float64\n",
      " 10  PC11    5187 non-null   float64\n",
      " 11  PC12    5187 non-null   float64\n",
      " 12  PC13    5187 non-null   float64\n",
      " 13  PC14    5187 non-null   float64\n",
      " 14  PC15    5187 non-null   float64\n",
      " 15  PC16    5187 non-null   float64\n",
      " 16  PC17    5187 non-null   float64\n",
      " 17  PC18    5187 non-null   float64\n",
      " 18  PC19    5187 non-null   float64\n",
      " 19  PC20    5187 non-null   float64\n",
      " 20  PC21    5187 non-null   float64\n",
      " 21  PC22    5187 non-null   float64\n",
      " 22  PC23    5187 non-null   float64\n",
      " 23  PC24    5187 non-null   float64\n",
      " 24  PC25    5187 non-null   float64\n",
      " 25  PC26    5187 non-null   float64\n",
      " 26  PC27    5187 non-null   float64\n",
      " 27  PC28    5187 non-null   float64\n",
      " 28  PC29    5187 non-null   float64\n",
      " 29  PC30    5187 non-null   float64\n",
      " 30  PC31    5187 non-null   float64\n",
      " 31  PC32    5187 non-null   float64\n",
      " 32  PC33    5187 non-null   float64\n",
      " 33  PC34    5187 non-null   float64\n",
      " 34  PC35    5187 non-null   float64\n",
      " 35  PC36    5187 non-null   float64\n",
      " 36  PC37    5187 non-null   float64\n",
      " 37  PC38    5187 non-null   float64\n",
      " 38  PC39    5187 non-null   float64\n",
      " 39  PC40    5187 non-null   float64\n",
      " 40  PC41    5187 non-null   float64\n",
      " 41  PC42    5187 non-null   float64\n",
      " 42  PC43    5187 non-null   float64\n",
      " 43  PC44    5187 non-null   float64\n",
      " 44  PC45    5187 non-null   float64\n",
      " 45  PC46    5187 non-null   float64\n",
      " 46  PC47    5187 non-null   float64\n",
      " 47  PC48    5187 non-null   float64\n",
      " 48  PC49    5187 non-null   float64\n",
      " 49  PC50    5187 non-null   float64\n",
      " 50  PC51    5187 non-null   float64\n",
      " 51  PC52    5187 non-null   float64\n",
      " 52  PC53    5187 non-null   float64\n",
      " 53  PC54    5187 non-null   float64\n",
      " 54  PC55    5187 non-null   float64\n",
      " 55  PC56    5187 non-null   float64\n",
      " 56  PC57    5187 non-null   float64\n",
      " 57  PC58    5187 non-null   float64\n",
      " 58  PC59    5187 non-null   float64\n",
      " 59  PC60    5187 non-null   float64\n",
      " 60  PC61    5187 non-null   float64\n",
      " 61  PC62    5187 non-null   float64\n",
      " 62  PC63    5187 non-null   float64\n",
      " 63  PC64    5187 non-null   float64\n",
      " 64  PC65    5187 non-null   float64\n",
      " 65  PC66    5187 non-null   float64\n",
      " 66  PC67    5187 non-null   float64\n",
      " 67  PC68    5187 non-null   float64\n",
      " 68  PC69    5187 non-null   float64\n",
      " 69  PC70    5187 non-null   float64\n",
      " 70  PC71    5187 non-null   float64\n",
      " 71  PC72    5187 non-null   float64\n",
      " 72  PC73    5187 non-null   float64\n",
      " 73  PC74    5187 non-null   float64\n",
      " 74  PC75    5187 non-null   float64\n",
      " 75  PC76    5187 non-null   float64\n",
      " 76  PC77    5187 non-null   float64\n",
      " 77  PC78    5187 non-null   float64\n",
      " 78  PC79    5187 non-null   float64\n",
      " 79  PC80    5187 non-null   float64\n",
      " 80  PC81    5187 non-null   float64\n",
      " 81  PC82    5187 non-null   float64\n",
      " 82  PC83    5187 non-null   float64\n",
      " 83  PC84    5187 non-null   float64\n",
      " 84  PC85    5187 non-null   float64\n",
      " 85  PC86    5187 non-null   float64\n",
      " 86  PC87    5187 non-null   float64\n",
      " 87  PC88    5187 non-null   float64\n",
      " 88  PC89    5187 non-null   float64\n",
      " 89  PC90    5187 non-null   float64\n",
      " 90  PC91    5187 non-null   float64\n",
      " 91  PC92    5187 non-null   float64\n",
      " 92  PC93    5187 non-null   float64\n",
      " 93  PC94    5187 non-null   float64\n",
      " 94  PC95    5187 non-null   float64\n",
      " 95  PC96    5187 non-null   float64\n",
      " 96  PC97    5187 non-null   float64\n",
      " 97  PC98    5187 non-null   float64\n",
      " 98  PC99    5187 non-null   float64\n",
      " 99  PC100   5187 non-null   float64\n",
      "dtypes: float64(100)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_pca.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e2fc0",
   "metadata": {},
   "source": [
    "# LASSO TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc942ffd",
   "metadata": {},
   "source": [
    "# Now onto our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b1759c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=27, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267f0bd",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression (MLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47657f68",
   "metadata": {},
   "source": [
    "## MLR - Initial Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94fd86f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.72      0.72       398\n",
      "         1.0       0.40      0.44      0.42       214\n",
      "         2.0       0.76      0.73      0.74       426\n",
      "\n",
      "    accuracy                           0.67      1038\n",
      "   macro avg       0.63      0.63      0.63      1038\n",
      "weighted avg       0.67      0.67      0.67      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_mlr = LogisticRegression(multi_class='multinomial', solver='lbfgs',\n",
    "                                   class_weight='balanced', max_iter=1000)\n",
    "\n",
    "model_mlr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_mlr.predict(X_test)\n",
    "print(\"Initial Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e48f2e6",
   "metadata": {},
   "source": [
    "## MLR- Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90092257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import GridSearchCV'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'C': 1e-05, 'solver': 'saga'}\n",
      "\n",
      "Tuned Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.73      0.72       398\n",
      "         1.0       0.45      0.35      0.39       214\n",
      "         2.0       0.72      0.79      0.76       426\n",
      "\n",
      "    accuracy                           0.67      1038\n",
      "   macro avg       0.63      0.62      0.62      1038\n",
      "weighted avg       0.66      0.67      0.67      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(multi_class='multinomial', class_weight='balanced', max_iter=1000),\n",
    "    param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters:\", grid.best_params_)\n",
    "\n",
    "y_pred_tuned = grid.predict(X_test)\n",
    "print(\"\\nTuned Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_tuned, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a8a0ee",
   "metadata": {},
   "source": [
    "# Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ec652",
   "metadata": {},
   "source": [
    "## RF - Initial Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e20923b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.77      0.73       398\n",
      "         1.0       0.51      0.17      0.25       214\n",
      "         2.0       0.69      0.85      0.76       426\n",
      "\n",
      "    accuracy                           0.68      1038\n",
      "   macro avg       0.63      0.59      0.58      1038\n",
      "weighted avg       0.65      0.68      0.64      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=27, class_weight='balanced')\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred = model_rf.predict(X_test)\n",
    "\n",
    "print(\"\\nInitial Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6de09",
   "metadata": {},
   "source": [
    "## RF - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "654ad1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': 27, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 689}\n",
      "\n",
      "Tuned RF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.77      0.75       398\n",
      "         1.0       0.55      0.29      0.38       214\n",
      "         2.0       0.70      0.83      0.76       426\n",
      "\n",
      "    accuracy                           0.70      1038\n",
      "   macro avg       0.66      0.63      0.63      1038\n",
      "weighted avg       0.68      0.70      0.68      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': randint(50, 1000),\n",
    "    'max_depth': randint(2, 50),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=model_rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=27\n",
    ")\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\", rand_search.best_params_)\n",
    "\n",
    "print(\"\\nTuned RF Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dbce9",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bad4bb",
   "metadata": {},
   "source": [
    "## SVM- Initial Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6f91746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.75      0.73       398\n",
      "         1.0       0.39      0.38      0.38       214\n",
      "         2.0       0.76      0.73      0.75       426\n",
      "\n",
      "    accuracy                           0.67      1038\n",
      "   macro avg       0.62      0.62      0.62      1038\n",
      "weighted avg       0.67      0.67      0.67      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_svm = svm.SVC(kernel=\"linear\", random_state=27, class_weight='balanced')\n",
    "\n",
    "model_svm.fit(X_train, y_train)\n",
    "y_pred = model_svm.predict(X_test)\n",
    "\n",
    "print(\"\\nInitial Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b631bc4d",
   "metadata": {},
   "source": [
    "## SVM - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0caa2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import GridSearchCV'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "Best Parameters: {'C': 5, 'kernel': 'rbf'}\n",
      "\n",
      "Tuned Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.75      0.73       398\n",
      "         1.0       0.46      0.40      0.43       214\n",
      "         2.0       0.75      0.75      0.75       426\n",
      "\n",
      "    accuracy                           0.68      1038\n",
      "   macro avg       0.64      0.63      0.64      1038\n",
      "weighted avg       0.67      0.68      0.68      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 5],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model_svm,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters:\", grid.best_params_)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"\\nTuned Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef40e9",
   "metadata": {},
   "source": [
    "# XGBoost (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db848605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.80      0.76       398\n",
      "         1.0       0.49      0.27      0.34       214\n",
      "         2.0       0.72      0.81      0.76       426\n",
      "\n",
      "    accuracy                           0.69      1038\n",
      "   macro avg       0.64      0.62      0.62      1038\n",
      "weighted avg       0.67      0.69      0.67      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(objective='multi:softmax', num_class=3, eval_metric='mlogloss', use_label_encoder=False)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "print(\"\\nInitial Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ef8db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "Best Hyperparameters: {'colsample_bytree': 0.500728347620244, 'gamma': 0.3369354595593149, 'learning_rate': 0.07172079621340263, 'max_depth': 9, 'n_estimators': 254, 'reg_alpha': 0.16981215156572083, 'reg_lambda': 5.775213080688159, 'subsample': 0.6197745550616657}\n",
      "\n",
      "Tuned Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.81      0.76       398\n",
      "         1.0       0.53      0.27      0.36       214\n",
      "         2.0       0.73      0.84      0.78       426\n",
      "\n",
      "    accuracy                           0.71      1038\n",
      "   macro avg       0.66      0.64      0.63      1038\n",
      "weighted avg       0.69      0.71      0.69      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 500),       \n",
    "    'max_depth': randint(3, 15),      \n",
    "    'learning_rate': uniform(0.01, 0.3),   \n",
    "    'subsample': uniform(0.5, 0.5),      \n",
    "    'colsample_bytree': uniform(0.5, 0.5), \n",
    "    'gamma': uniform(0, 5),       \n",
    "    'reg_alpha': uniform(0, 1),  \n",
    "    'reg_lambda': uniform(1, 5)   \n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=model_xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,              \n",
    "    cv=5,                \n",
    "    scoring='accuracy',  \n",
    "    n_jobs=-1,      \n",
    "    random_state=27,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = rand_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\", rand_search.best_params_)\n",
    "print(\"\\nTuned Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e8430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5a026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ab501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0a7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
